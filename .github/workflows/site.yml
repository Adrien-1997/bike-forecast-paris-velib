name: Build & Deploy Monitoring Site (with Auto Retrain)

on:
  push:
    branches: [ main ]
  schedule:
    - cron: "0 */6 * * *"
  workflow_dispatch:

permissions:
  contents: write

jobs:
  build-monitor:
    runs-on: ubuntu-latest
    env:
      MPLBACKEND: Agg
      TZ: Europe/Paris
    concurrency:
      group: pages-build
      cancel-in-progress: false
    outputs:
      need_retrain: ${{ steps.check.outputs.need_retrain }}
      max_psi: ${{ steps.check.outputs.max_psi }}
      mae_24h: ${{ steps.check.outputs.mae_24h }}
      mae_baseline: ${{ steps.check.outputs.mae_baseline }}
    steps:
      - uses: actions/checkout@v4
        with: { fetch-depth: 0 }

      - uses: actions/setup-python@v5
        with: { python-version: "3.11" }

      - uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-docs-${{ hashFiles('requirements-doc.txt') }}
          restore-keys: ${{ runner.os }}-pip-docs-

      - name: Install deps (docs + jq + HF)
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-doc.txt huggingface_hub
          sudo apt-get update && sudo apt-get install -y jq git-lfs

      # --- Download exports from Hugging Face (auth + checks) ---
      - name: Download velib exports from HF
        shell: bash
        env:
          HF_DATASET: ${{ vars.HF_DATASET }}      # ex: adrien97/velib-monitoring-historical
          HF_TOKEN: ${{ secrets.HF_TOKEN }}        # token HF read
        run: |
          set -euo pipefail
          if [[ -z "${HF_DATASET:-}" ]]; then
            echo "HF_DATASET not set (Settings → Actions → Variables). Expected 'user/repo'."; exit 1
          fi
          if [[ -z "${HF_TOKEN:-}" ]]; then
            echo "HF_TOKEN not set (Settings → Actions → Secrets)."; exit 1
          fi
          git lfs install
          rm -rf hf-ds
          # injecte le token pour cloner un dataset privé
          HF_USER="${HF_DATASET%%/*}"
          git clone "https://${HF_USER}:${HF_TOKEN}@huggingface.co/datasets/${HF_DATASET}" hf-ds
          mkdir -p docs/exports
          cp -v hf-ds/exports/velib.parquet docs/exports/velib.parquet || true
          cp -v hf-ds/exports/velib.csv     docs/exports/velib.csv     || true
          ls -lh docs/exports || true

      - name: Build monitoring artifacts
        run: |
          python tools/build_monitoring.py \
            --tz Europe/Paris \
            --horizon 60 \
            --last-days 14 \
            --current-days 7 \
            --reference-days 28

      - name: Decide retrain (PSI/perf)
        id: check
        env:
          THRESH_PSI: "0.20"
          THRESH_MAE_PCT: "1.20"
        run: |
          python tools/check_retrain.py | tee check.json
          echo "need_retrain=$(jq -r '.need_retrain' check.json)"   >> "$GITHUB_OUTPUT"
          echo "max_psi=$(jq -r '.max_psi' check.json)"             >> "$GITHUB_OUTPUT"
          echo "mae_24h=$(jq -r '.mae_24h' check.json)"             >> "$GITHUB_OUTPUT"
          echo "mae_baseline=$(jq -r '.mae_baseline' check.json)"   >> "$GITHUB_OUTPUT"

      - name: Build MkDocs
        run: mkdocs build --clean

      - name: Deploy to gh-pages
        uses: peaceiris/actions-gh-pages@v3
        if: always()
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./site
          force_orphan: true

  retrain-and-rebuild:
    needs: build-monitor
    if: needs.build-monitor.outputs.need_retrain == 'true'
    runs-on: ubuntu-latest
    env:
      MPLBACKEND: Agg
      TZ: Europe/Paris
    concurrency:
      group: pages-build
      cancel-in-progress: false
    steps:
      - uses: actions/checkout@v4
        with: { fetch-depth: 0 }

      - uses: actions/setup-python@v5
        with: { python-version: "3.11" }

      - uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-train-${{ hashFiles('requirements-*.txt') }}
          restore-keys: ${{ runner.os }}-pip-train-

      - name: Install deps (train + docs + HF)
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-train.txt
          pip install -r requirements-doc.txt huggingface_hub
          sudo apt-get update && sudo apt-get install -y git-lfs

      # --- Download exports from Hugging Face (auth + checks) ---
      - name: Download velib exports from HF
        shell: bash
        env:
          HF_DATASET: ${{ vars.HF_DATASET }}
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          set -euo pipefail
          if [[ -z "${HF_DATASET:-}" ]]; then
            echo "HF_DATASET not set (Settings → Actions → Variables). Expected 'user/repo'."; exit 1
          fi
          if [[ -z "${HF_TOKEN:-}" ]]; then
            echo "HF_TOKEN not set (Settings → Actions → Secrets)."; exit 1
          fi
          git lfs install
          rm -rf hf-ds
          HF_USER="${HF_DATASET%%/*}"
          git clone "https://${HF_USER}:${HF_TOKEN}@huggingface.co/datasets/${HF_DATASET}" hf-ds
          mkdir -p docs/exports
          cp -v hf-ds/exports/velib.parquet docs/exports/velib.parquet || true
          cp -v hf-ds/exports/velib.csv     docs/exports/velib.csv     || true
          ls -lh docs/exports || true

      - name: Retrain LightGBM (T+60)
        run: |
          python - << 'PY'
          from src.forecast import train
          res = train(horizon_minutes=60, lookback_days=30)
          print(res)
          import json, pathlib
          p = pathlib.Path("docs/exports"); p.mkdir(parents=True, exist_ok=True)
          with open(p/"baseline.json", "w", encoding="utf-8", newline="") as f:
              json.dump(
                  {"mae_valid": res["mae"], "rmse_valid": res["rmse"], "n_valid": res["n_valid"]},
                  f, indent=2, ensure_ascii=False
              )
          PY

      - name: Commit new model + baseline
        run: |
          set -euxo pipefail
          git config user.name  "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add -f docs/exports/baseline.json || true
          git add -f models/*.joblib || true
          git commit -m "ci(retrain): update model & baseline [skip ci]" || echo "no changes"
          git fetch origin main
          git -c rebase.autoStash=true pull --rebase origin main
          git push origin HEAD:main

      - name: Rebuild monitoring
        run: |
          python tools/build_monitoring.py \
            --tz Europe/Paris \
            --horizon 60 \
            --last-days 14 \
            --current-days 7 \
            --reference-days 28
          mkdocs build --clean

      - name: Deploy to gh-pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./site
          force_orphan: true
