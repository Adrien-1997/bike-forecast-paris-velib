name: velib-ingest

on:
  schedule:
    # Quarts d’heure précis en UTC → 01,16,31,46
    - cron: "1,16,31,46 * * * *"
  workflow_dispatch:

permissions:
  contents: write

concurrency:
  group: velib-ingest
  cancel-in-progress: true

jobs:
  ingest_aggregate:
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install pipeline deps
        run: |
          python -m pip install -U pip
          pip install -r requirements-pipeline.txt
          # si huggingface_hub n'est pas dans requirements-pipeline.txt, décommente:
          # pip install huggingface_hub

      - name: Ingest snapshot (OpenData → DuckDB)
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: python -m src.ingest

      - name: Aggregate 15min + weather → docs/exports/
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: python -m src.aggregate

      - name: Inspect exports
        shell: bash
        run: |
          echo "=== Exports present? ==="
          ls -lh docs/exports || true
          python - <<'PY'
          import pandas as pd, pathlib
          p = pathlib.Path("docs/exports/velib.parquet")
          if p.exists():
              df = pd.read_parquet(p)
              print("[ingest] rows:", len(df), "stations:", df['stationcode'].nunique())
              print("[ingest] span:", df['tbin_utc'].min(), "->", df['tbin_utc'].max())
          else:
              print("[ingest] docs/exports/velib.parquet NOT FOUND")
          PY

      # --- NEW: push exports to Hugging Face dataset ---
      - name: Install Hugging Face CLI
        run: pip install -q huggingface_hub && git lfs install

      - name: Login to Hugging Face
        run: huggingface-cli login --token $HF_TOKEN
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}

      - name: Push velib exports (parquet/csv) to HF dataset
        shell: bash
        env:
          HF_DATASET: ${{ vars.HF_DATASET }}
        run: |
          set -e
          rm -rf hf-ds
          git clone https://huggingface.co/datasets/${HF_DATASET} hf-ds

          mkdir -p hf-ds/exports
          [ -f docs/exports/velib.parquet ] && cp -v docs/exports/velib.parquet hf-ds/exports/velib.parquet || true
          [ -f docs/exports/velib.csv ] && cp -v docs/exports/velib.csv hf-ds/exports/velib.csv || true

          cd hf-ds
          git add .
          git commit -m "Update velib exports from ingest (15min)" || echo "Nothing to commit"
          git push

      # (SUPPRIMÉ) plus de commit des data dans GitHub
      # - name: Commit data if changed
      #   run: ...
