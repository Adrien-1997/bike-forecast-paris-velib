name: velib-ingest

on:
  schedule:
    # Toutes les 5 minutes (UTC). On décale de 60s dans le job pour laisser la source publier.
    - cron: "*/5 * * * *"
  workflow_dispatch:

permissions:
  contents: write

concurrency:
  group: velib-ingest
  cancel-in-progress: true

jobs:
  ingest_aggregate:
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install pipeline deps
        run: |
          python -m pip install -U pip
          pip install -r requirements-pipeline.txt

      # Petit tampon pour laisser l'OpenData publier (équiv. à ton 1-59/5)
      - name: Offset start by ~60s
        run: sleep 60

      - name: Ingest snapshot (OpenData → DuckDB)
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: python -m src.ingest

      - name: Aggregate 5min + weather → docs/exports/
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: python -m src.aggregate

      - name: Inspect exports
        shell: bash
        run: |
          echo "=== Exports present? ==="
          ls -lh docs/exports || true
          python -c "import pathlib, pandas as pd; p=pathlib.Path('docs/exports/velib.parquet'); print('[ingest] file exists:', p.exists()); \
                     (print('[ingest] rows:', len(pd.read_parquet(p)), 'stations:', pd.read_parquet(p)['stationcode'].nunique()) if p.exists() else None)"

      # ------------ Hugging Face ------------
      - name: Install Hugging Face CLI
        run: |
          python -m pip install -U huggingface_hub
          git lfs install

      - name: Login to Hugging Face
        shell: bash
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          set -euo pipefail
          if [[ -z "${HF_TOKEN:-}" ]]; then
            echo "HF_TOKEN is empty or not set. Define repository secret HF_TOKEN."
            exit 1
          fi
          huggingface-cli login --token "${HF_TOKEN}" --add-to-git-credential
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git config --global user.name "github-actions[bot]"

      - name: Push velib exports (parquet/csv) to HF dataset
        shell: bash
        env:
          HF_DATASET: ${{ vars.HF_DATASET }}   # ex: "adrien/velib-paris-exports"
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          set -euo pipefail

          if [[ -z "${HF_DATASET:-}" || -z "${HF_TOKEN:-}" ]]; then
            echo "HF_DATASET or HF_TOKEN missing"
            exit 1
          fi

          rm -rf hf-ds
          git clone "https://huggingface.co/datasets/${HF_DATASET}" hf-ds

          mkdir -p hf-ds/exports
          [[ -f docs/exports/velib.parquet ]] && cp -v docs/exports/velib.parquet hf-ds/exports/velib.parquet || true
          [[ -f docs/exports/velib.csv     ]] && cp -v docs/exports/velib.csv     hf-ds/exports/velib.csv     || true

          cd hf-ds
          git add -A
          git commit -m "Update velib exports from ingest (5min)" || echo "Nothing to commit"

          HF_USER="${HF_DATASET%%/*}"
          git remote set-url origin "https://${HF_USER}:${HF_TOKEN}@huggingface.co/datasets/${HF_DATASET}"

          git push origin main
